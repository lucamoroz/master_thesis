\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{english}{}
\citation{BO}
\@writefile{toc}{\contentsline {section}{\numberline {1} Introduction }{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2} Context and State of the Art }{1}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1} Bayesian Optimization }{1}{subsection.2.1}\protected@file@percent }
\newlabel{eq:bo_optimization}{{1}{1}{Bayesian Optimization}{equation.2.1}{}}
\newlabel{fig:bo}{{2.1}{2}{Bayesian Optimization}{equation.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A few iterations of BO. The acquisition function in green guides the selection of the next point, obtaining a new observation $(\pmb  {x}_i, y_i)$}}{2}{figure.1}\protected@file@percent }
\citation{BO}
\citation{AkamasCGP}
\citation{CGPBanditOptimization}
\citation{AkamasCGP}
\newlabel{fig:multitask_bo}{{2.1}{3}{Bayesian Optimization}{figure.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Multitask Bayesian Optimization.}}{3}{figure.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Contextual Bayesian Optimization of IT systems}{3}{subsubsection.2.1.1}\protected@file@percent }
\newlabel{ssec:contextual_bayesian_optimization}{{2.1.1}{3}{Contextual Bayesian Optimization of IT systems}{subsubsection.2.1.1}{}}
\citation{AkamasCGP}
\citation{AkamasCGP}
\citation{AkamasCGP}
\newlabel{fig:cgp_it_sys}{{2.1.1}{4}{Contextual Bayesian Optimization of IT systems}{subsubsection.2.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Tuning process - TODO disallineata}}{4}{figure.3}\protected@file@percent }
\citation{WorkloadCharacterization}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Workload characterization}{5}{subsection.2.2}\protected@file@percent }
\newlabel{ssec:workload_characterization}{{2.2}{5}{Workload characterization}{subsection.2.2}{}}
\citation{PearsonCoefficient}
\citation{WorkloadCharacterization}
\citation{ClusteringSurvey}
\citation{ClusteringSurvey}
\citation{PCA}
\citation{WorkloadsPowerLaw}
\citation{ForecastingSurvey}
\citation{ExponentialSmoothingHoltCharles}
\citation{ForecastingBoxJenkins}
\citation{25YearsForecasting}
\citation{25YearsForecasting}
\citation{DeepLearningForecastingSurvey}
\citation{RNNLSTM}
\citation{seq2seq}
\citation{EncoderDecoder}
\citation{DeepAR}
\citation{DeepState}
\citation{DeepLearningForecastingSurvey}
\citation{MAKRIDAKIS2018802}
\citation{GluonTS}
\citation{MAKRIDAKIS2018802}
\citation{UberHybridES}
\citation{M5Competition}
\citation{FacebookProphet}
\citation{MAKRIDAKIS2018802}
\citation{M5Competition}
\citation{FacebookProphet}
\citation{GluonTS}
\citation{MicrosoftSSA}
\citation{UberHybridES}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3} Clustering }{6}{subsection.2.3}\protected@file@percent }
\newlabel{ssec:clustering}{{2.3}{6}{Clustering}{subsection.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4} Forecasting }{6}{subsection.2.4}\protected@file@percent }
\newlabel{sec:forecasting}{{2.4}{6}{Forecasting}{subsection.2.4}{}}
\citation{DeepLearningForecastingSurvey}
\citation{FacebookProphet}
\citation{ForecastingHyndmanAthanasopoulos}
\citation{STL}
\citation{ForecastingHyndmanAthanasopoulos}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Four time series examples. Top left: seasonality and cycle; top right: trend only; bottom left: trend and seasonality; bottom right: random fluctuations}}{8}{figure.4}\protected@file@percent }
\newlabel{eq:forecasting}{{2}{8}{Forecasting}{equation.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Additive decomposition of a time series using STL}}{9}{figure.5}\protected@file@percent }
\newlabel{fig:stl}{{5}{9}{Additive decomposition of a time series using STL}{figure.5}{}}
\citation{M5Competition}
\citation{FacebookProphet}
\citation{DeepAR}
\citation{DeepState}
\citation{DiscriminativeGenerativeModels}
\citation{GluonTS}
\citation{ExponentialSmoothingHoltCharles}
\citation{ExponentialSmoothingHoltCharles}
\newlabel{table:generativediscriminative}{{2.4}{10}{Forecasting}{equation.2.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Forecasting models}}{10}{table.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.1}Exponential Smoothing}{10}{subsubsection.2.4.1}\protected@file@percent }
\newlabel{sssec:exponential_smoothing}{{2.4.1}{10}{Exponential Smoothing}{subsubsection.2.4.1}{}}
\citation{ExponentialSmoothingStateSpace}
\citation{BoxJenkins}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.2}ARMA models}{11}{subsubsection.2.4.2}\protected@file@percent }
\newlabel{sssec:arma}{{2.4.2}{11}{ARMA models}{subsubsection.2.4.2}{}}
\citation{AutoForecasting}
\citation{25YearsForecasting}
\citation{FacebookProphet}
\citation{GAM}
\citation{L-BFGS}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.3} Prophet }{12}{subsubsection.2.4.3}\protected@file@percent }
\newlabel{sssec:prohet}{{2.4.3}{12}{Prophet}{subsubsection.2.4.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Prophet analyst-in-the-loop approach}}{13}{figure.6}\protected@file@percent }
\newlabel{fig:analyst_in_the_loop}{{6}{13}{Prophet analyst-in-the-loop approach}{figure.6}{}}
\citation{RNNForecasting}
\citation{M5Competition}
\citation{RNN}
\citation{RNNForecasting}
\citation{VanishingGradient}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.4}ML models}{14}{subsubsection.2.4.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Architecture of an Elman recurrent unit, LSTM, and GRU. The output at step $t-1$ influences the output at step $t$.}}{15}{figure.7}\protected@file@percent }
\newlabel{fig:lstmgru}{{7}{15}{Architecture of an Elman recurrent unit, LSTM, and GRU. The output at step $t-1$ influences the output at step $t$}{figure.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces RNN architectures. Red rectangles are input vectors, blue rectangles are output vectors, and green rectangles are recurrent units such as LSTM or GRU which share the same weights while their state evolves from left to right.}}{15}{figure.8}\protected@file@percent }
\newlabel{fig:rnn_architectures}{{8}{15}{RNN architectures. Red rectangles are input vectors, blue rectangles are output vectors, and green rectangles are recurrent units such as LSTM or GRU which share the same weights while their state evolves from left to right}{figure.8}{}}
\citation{seq2seq}
\citation{DeepAR}
\citation{MQCNN}
\citation{NARX}
\citation{DeepAR}
\citation{MQCNN}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces 2-layers stacked LSTMs. }}{16}{figure.9}\protected@file@percent }
\newlabel{fig:stacked_lstm}{{9}{16}{2-layers stacked LSTMs}{figure.9}{}}
\citation{DeepAR}
\citation{seq2seq}
\citation{DeepAR}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Sequence to sequence model}}{17}{figure.10}\protected@file@percent }
\newlabel{fig:seq2seq}{{10}{17}{Sequence to sequence model}{figure.10}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.5} DeepAR }{17}{subsubsection.2.4.5}\protected@file@percent }
\newlabel{sssec:deepar}{{2.4.5}{17}{DeepAR}{subsubsection.2.4.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces DeepAR decoder network}}{18}{figure.11}\protected@file@percent }
\newlabel{fig:deepar}{{11}{18}{DeepAR decoder network}{figure.11}{}}
\newlabel{eq:autoregressive_rnn}{{3}{18}{DeepAR}{equation.2.3}{}}
\citation{DeepAR}
\citation{DeepState}
\citation{ExponentialSmoothingStateSpace}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.6} DeepState }{19}{subsubsection.2.4.6}\protected@file@percent }
\newlabel{sssec:deepstate}{{2.4.6}{19}{DeepState}{subsubsection.2.4.6}{}}
\citation{MQCNN}
\citation{MQCNN}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces DeepState network}}{20}{figure.12}\protected@file@percent }
\newlabel{fig:deepstate}{{12}{20}{DeepState network}{figure.12}{}}
\newlabel{eq:deepstate}{{4}{20}{DeepState}{equation.2.4}{}}
\citation{DeepAR}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces DeepState forecast illustration}}{21}{figure.13}\protected@file@percent }
\newlabel{fig:deepstate2}{{13}{21}{DeepState forecast illustration}{figure.13}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.7} Multi Quantile Recurrent Forecaster }{21}{subsubsection.2.4.7}\protected@file@percent }
\newlabel{sssec:mqcnn}{{2.4.7}{21}{Multi Quantile Recurrent Forecaster}{subsubsection.2.4.7}{}}
\citation{MQCNN}
\citation{MQCNN}
\citation{Wavenet}
\citation{CloudComputing}
\citation{ArimaWorkloadPrediction}
\citation{ArimaWorkloadPrediction}
\citation{ArmaAutoscaling}
\citation{WorkloadCharacterizationAndPrediction}
\citation{LSTMLargeScaleWorkloadForecasting}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Multi-quantile recurrent forecaster architecture}}{22}{figure.14}\protected@file@percent }
\newlabel{fig:mqforecaster}{{14}{22}{Multi-quantile recurrent forecaster architecture}{figure.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5} Workload forecasting }{22}{subsection.2.5}\protected@file@percent }
\newlabel{ssec:workload_forecasting}{{2.5}{22}{Workload forecasting}{subsection.2.5}{}}
\citation{Seagull}
\citation{MicrosoftSSA}
\citation{GluonTS}
\citation{FacebookProphet}
\citation{Seagull}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces A stack of dilated causal convolutional layers}}{23}{figure.15}\protected@file@percent }
\newlabel{fig:dilated_cnn}{{15}{23}{A stack of dilated causal convolutional layers}{figure.15}{}}
\citation{AkamasCGP}
\@writefile{toc}{\contentsline {section}{\numberline {3} Proposed solution and approach }{24}{section.3}\protected@file@percent }
\citation{Seagull}
\newlabel{table:stability_cases}{{3.1}{25}{Online Contextual Gaussian Process Tuner}{subsection.3.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Window stability outcomes. TP, FP, TN, FN stands for True Positive, False Positive, True Negative, and False negative respectively.}}{25}{table.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Online Contextual Gaussian Process Tuner}{25}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Forecasting module}{27}{subsection.3.2}\protected@file@percent }
\newlabel{ssec:forecasting_module}{{3.2}{27}{Forecasting module}{subsection.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Stable window finder}{28}{subsection.3.3}\protected@file@percent }
\newlabel{ssec:stable_window_finder}{{3.3}{28}{Stable window finder}{subsection.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Workload characterization module}{29}{subsection.3.4}\protected@file@percent }
\newlabel{ssec:workload_characterization_module}{{3.4}{29}{Workload characterization module}{subsection.3.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4} Experimental setup }{30}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5} Results }{30}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6} Conclusions }{30}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7} Future work }{30}{section.7}\protected@file@percent }
\bibdata{bibliography.bib}
\bibcite{BO}{1}
\bibcite{AkamasCGP}{2}
\bibcite{CGPBanditOptimization}{3}
\bibcite{WorkloadCharacterization}{4}
\bibcite{PearsonCoefficient}{5}
\bibcite{ClusteringSurvey}{6}
\bibcite{PCA}{7}
\bibcite{WorkloadsPowerLaw}{8}
\bibcite{ForecastingSurvey}{9}
\bibcite{ExponentialSmoothingHoltCharles}{10}
\bibcite{ForecastingBoxJenkins}{11}
\bibcite{25YearsForecasting}{12}
\bibcite{DeepLearningForecastingSurvey}{13}
\bibcite{RNNLSTM}{14}
\bibcite{seq2seq}{15}
\bibcite{EncoderDecoder}{16}
\bibcite{DeepAR}{17}
\bibcite{DeepState}{18}
\bibcite{MAKRIDAKIS2018802}{19}
\bibcite{GluonTS}{20}
\bibcite{UberHybridES}{21}
\bibcite{M5Competition}{22}
\bibcite{FacebookProphet}{23}
\bibcite{MicrosoftSSA}{24}
\bibcite{ForecastingHyndmanAthanasopoulos}{25}
\bibcite{STL}{26}
\bibcite{DiscriminativeGenerativeModels}{27}
\bibcite{ExponentialSmoothingStateSpace}{28}
\bibcite{BoxJenkins}{29}
\bibcite{AutoForecasting}{30}
\bibcite{GAM}{31}
\bibcite{L-BFGS}{32}
\bibcite{RNNForecasting}{33}
\bibcite{RNN}{34}
\bibcite{VanishingGradient}{35}
\bibcite{MQCNN}{36}
\bibcite{NARX}{37}
\bibcite{Wavenet}{38}
\bibcite{CloudComputing}{39}
\bibcite{ArimaWorkloadPrediction}{40}
\bibcite{ArmaAutoscaling}{41}
\bibcite{WorkloadCharacterizationAndPrediction}{42}
\bibcite{LSTMLargeScaleWorkloadForecasting}{43}
\bibcite{Seagull}{44}
\bibstyle{ieeetr}
\gdef \@abspage@last{40}
