\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{english}{}
\citation{AkamasCGP}
\citation{LearningToSample}
\citation{OtterTune}
\citation{OtterTune2}
\citation{AkamasCGP}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction }{1}{section.1}\protected@file@percent }
\newlabel{fig:online_tuning}{{1}{2}{Introduction }{section.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Online tuning: while the system is receiving its workload (e.g. a set of HTTP requests) the tuner uses the system metrics to suggest new configurations that may improve the performance or reduce infrastructure costs.}}{2}{figure.1}\protected@file@percent }
\citation{AkamasCGP}
\citation{OtterTune}
\citation{OtterTune2}
\citation{LearningToSample}
\citation{AkamasCGP}
\citation{AkamasCGP}
\citation{AkamasCGP}
\citation{BO}
\@writefile{toc}{\contentsline {section}{\numberline {2}Context and State of the Art }{3}{section.2}\protected@file@percent }
\newlabel{sec:context_and_state_of_the_art}{{2}{3}{Context and State of the Art }{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Bayesian Optimization }{4}{subsection.2.1}\protected@file@percent }
\newlabel{ssec:bayesian_optimization}{{2.1}{4}{Bayesian Optimization }{subsection.2.1}{}}
\newlabel{eq:bo_optimization}{{1}{4}{Bayesian Optimization }{equation.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces A few iterations of BO. The acquisition function $u(\cdot )$ (green) guides the selection of the next point, obtaining a new observation $(\pmb  {x}_i, y_i)$ that updates the underlying model of the unknown function $f(\cdot )$.}}{5}{figure.2}\protected@file@percent }
\newlabel{fig:bo}{{2}{5}{A few iterations of BO. The acquisition function $u(\cdot )$ (green) guides the selection of the next point, obtaining a new observation $(\pmb {x}_i, y_i)$ that updates the underlying model of the unknown function $f(\cdot )$}{figure.2}{}}
\citation{BO}
\citation{AkamasCGP}
\citation{CGPBanditOptimization}
\citation{CGPBanditOptimization}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Contextual Bayesian Optimization of IT systems}{6}{subsubsection.2.1.1}\protected@file@percent }
\newlabel{ssec:contextual_bayesian_optimization}{{2.1.1}{6}{Contextual Bayesian Optimization of IT systems}{subsubsection.2.1.1}{}}
\citation{AkamasCGP}
\citation{AkamasCGP}
\citation{AkamasCGP}
\citation{AkamasCGP}
\citation{AkamasCGP}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Multitask Bayesian Optimization. The figure in the middle shows the posterior predictive distribution of the blue function (3) without exploiting the information of the other functions.}}{7}{figure.3}\protected@file@percent }
\newlabel{fig:multitask_bo}{{3}{7}{Multitask Bayesian Optimization. The figure in the middle shows the posterior predictive distribution of the blue function (3) without exploiting the information of the other functions}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces BO-based tuning process. Given the workload $\pmb  {w}_i$, the tuner uses the knowledge base to apply a new configuration $\pmb  {x}_i$ that is evaluated (obtaining $y_i$), growing the knowledge base.}}{8}{figure.4}\protected@file@percent }
\newlabel{fig:cgp_it_sys}{{4}{8}{BO-based tuning process. Given the workload $\pmb {w}_i$, the tuner uses the knowledge base to apply a new configuration $\pmb {x}_i$ that is evaluated (obtaining $y_i$), growing the knowledge base}{figure.4}{}}
\citation{WorkloadCharacterization}
\citation{PearsonCoefficient}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Workload Characterization}{10}{subsection.2.2}\protected@file@percent }
\newlabel{ssec:workload_characterization}{{2.2}{10}{Workload Characterization}{subsection.2.2}{}}
\citation{WorkloadCharacterization}
\citation{ClusteringSurvey}
\citation{ClusteringSurvey}
\citation{PCA}
\citation{WorkloadsPowerLaw}
\citation{ClusteringSurvey}
\citation{ClusterHomogeinitySeparation}
\citation{FuzzyClustering}
\citation{HierarchicalClustering}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Common clustering procedure.}}{12}{figure.5}\protected@file@percent }
\newlabel{fig:clustering_approach}{{5}{12}{Common clustering procedure}{figure.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Clustering }{12}{subsection.2.3}\protected@file@percent }
\newlabel{ssec:clustering}{{2.3}{12}{Clustering }{subsection.2.3}{}}
\citation{ImpossibleTheoremForClustering}
\citation{kmeans++}
\citation{MeanShift}
\citation{OPTICS}
\citation{MixtureModels}
\citation{SilhouetteCoefficient}
\citation{BayesianInformationCriterion}
\citation{ForecastingSurvey}
\citation{ExponentialSmoothingHoltCharles}
\citation{ForecastingBoxJenkins}
\citation{25YearsForecasting}
\citation{25YearsForecasting}
\citation{DeepLearningForecastingSurvey}
\citation{RNNLSTM}
\citation{seq2seq}
\citation{EncoderDecoder}
\citation{DeepAR}
\citation{DeepState}
\citation{DeepLearningForecastingSurvey}
\citation{MAKRIDAKIS2018802}
\citation{GluonTS}
\citation{MAKRIDAKIS2018802}
\citation{UberHybridES}
\citation{M5Competition}
\citation{FacebookProphet}
\citation{MAKRIDAKIS2018802}
\citation{M5Competition}
\citation{FacebookProphet}
\citation{GluonTS}
\citation{MicrosoftSSA}
\citation{UberHybridES}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Forecasting }{14}{subsection.2.4}\protected@file@percent }
\newlabel{sec:forecasting}{{2.4}{14}{Forecasting }{subsection.2.4}{}}
\citation{DeepLearningForecastingSurvey}
\citation{FacebookProphet}
\citation{ForecastingHyndmanAthanasopoulos}
\citation{STL}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Four time series examples. Top left: seasonality and cycle; top right: trend only; bottom left: trend and seasonality; bottom right: random fluctuations.}}{16}{figure.6}\protected@file@percent }
\newlabel{fig:time_series_components}{{6}{16}{Four time series examples. Top left: seasonality and cycle; top right: trend only; bottom left: trend and seasonality; bottom right: random fluctuations}{figure.6}{}}
\citation{ForecastingHyndmanAthanasopoulos}
\newlabel{eq:forecasting}{{2}{17}{Forecasting }{equation.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Additive decomposition of a time series using STL.}}{18}{figure.7}\protected@file@percent }
\newlabel{fig:stl}{{7}{18}{Additive decomposition of a time series using STL}{figure.7}{}}
\citation{M5Competition}
\citation{FacebookProphet}
\citation{DeepAR}
\citation{DeepState}
\citation{DiscriminativeGenerativeModels}
\citation{GluonTS}
\citation{ExponentialSmoothingHoltCharles}
\citation{ExponentialSmoothingHoltCharles}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Forecasting models.}}{19}{table.1}\protected@file@percent }
\newlabel{table:generativediscriminative}{{1}{19}{Forecasting models}{table.1}{}}
\citation{ExponentialSmoothingStateSpace}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.1}Exponential Smoothing}{20}{subsubsection.2.4.1}\protected@file@percent }
\newlabel{sssec:exponential_smoothing}{{2.4.1}{20}{Exponential Smoothing}{subsubsection.2.4.1}{}}
\citation{BoxJenkins}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.2}ARMA models}{21}{subsubsection.2.4.2}\protected@file@percent }
\newlabel{sssec:arma}{{2.4.2}{21}{ARMA models}{subsubsection.2.4.2}{}}
\citation{AutoForecasting}
\citation{25YearsForecasting}
\citation{FacebookProphet}
\citation{GAM}
\citation{L-BFGS}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.3}Prophet }{22}{subsubsection.2.4.3}\protected@file@percent }
\newlabel{sssec:prohet}{{2.4.3}{22}{Prophet }{subsubsection.2.4.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Prophet analyst-in-the-loop approach.}}{23}{figure.8}\protected@file@percent }
\newlabel{fig:analyst_in_the_loop}{{8}{23}{Prophet analyst-in-the-loop approach}{figure.8}{}}
\newlabel{eq:trend_model}{{3}{24}{Prophet }{equation.2.3}{}}
\citation{RNNForecasting}
\citation{M5Competition}
\citation{RNN}
\citation{RNNForecasting}
\citation{VanishingGradient}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.4}ML models}{25}{subsubsection.2.4.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Architecture of an Elman recurrent unit, LSTM, and GRU. The output at step $t-1$ influences the output at step $t$.}}{26}{figure.9}\protected@file@percent }
\newlabel{fig:lstmgru}{{9}{26}{Architecture of an Elman recurrent unit, LSTM, and GRU. The output at step $t-1$ influences the output at step $t$}{figure.9}{}}
\citation{seq2seq}
\citation{DeepAR}
\citation{MQCNN}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces RNN architectures. Red rectangles are input vectors, blue rectangles are output vectors, and green rectangles are recurrent units such as LSTM or GRU which share the same weights while their state evolves from left to right.}}{27}{figure.10}\protected@file@percent }
\newlabel{fig:rnn_architectures}{{10}{27}{RNN architectures. Red rectangles are input vectors, blue rectangles are output vectors, and green rectangles are recurrent units such as LSTM or GRU which share the same weights while their state evolves from left to right}{figure.10}{}}
\citation{NARX}
\citation{DeepAR}
\citation{MQCNN}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces 2-layers stacked LSTMs. }}{28}{figure.11}\protected@file@percent }
\newlabel{fig:stacked_lstm}{{11}{28}{2-layers stacked LSTMs}{figure.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Sequence to sequence model.}}{29}{figure.12}\protected@file@percent }
\newlabel{fig:seq2seq}{{12}{29}{Sequence to sequence model}{figure.12}{}}
\citation{DeepAR}
\citation{seq2seq}
\citation{DeepAR}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.5}DeepAR }{30}{subsubsection.2.4.5}\protected@file@percent }
\newlabel{sssec:deepar}{{2.4.5}{30}{DeepAR }{subsubsection.2.4.5}{}}
\newlabel{eq:autoregressive_rnn}{{4}{30}{DeepAR }{equation.2.4}{}}
\citation{DeepAR}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces DeepAR decoder network.}}{31}{figure.13}\protected@file@percent }
\newlabel{fig:deepar}{{13}{31}{DeepAR decoder network}{figure.13}{}}
\citation{DeepState}
\citation{ExponentialSmoothingStateSpace}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.6}DeepState }{32}{subsubsection.2.4.6}\protected@file@percent }
\newlabel{sssec:deepstate}{{2.4.6}{32}{DeepState }{subsubsection.2.4.6}{}}
\newlabel{eq:deepstate}{{5}{33}{DeepState }{equation.2.5}{}}
\citation{MQCNN}
\citation{MQCNN}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces DeepState network.}}{34}{figure.14}\protected@file@percent }
\newlabel{fig:deepstate}{{14}{34}{DeepState network}{figure.14}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.7}Multi Quantile Recurrent Forecaster }{34}{subsubsection.2.4.7}\protected@file@percent }
\newlabel{sssec:mqcnn}{{2.4.7}{34}{Multi Quantile Recurrent Forecaster }{subsubsection.2.4.7}{}}
\citation{DeepAR}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces DeepState forecast illustration.}}{35}{figure.15}\protected@file@percent }
\newlabel{fig:deepstate2}{{15}{35}{DeepState forecast illustration}{figure.15}{}}
\citation{MQCNN}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Multi-quantile recurrent forecaster architecture.}}{36}{figure.16}\protected@file@percent }
\newlabel{fig:mqforecaster}{{16}{36}{Multi-quantile recurrent forecaster architecture}{figure.16}{}}
\citation{MQCNN}
\citation{Wavenet}
\citation{CloudComputing}
\citation{ArimaWorkloadPrediction}
\citation{ArimaWorkloadPrediction}
\citation{ArmaAutoscaling}
\citation{WorkloadCharacterizationAndPrediction}
\citation{LSTMLargeScaleWorkloadForecasting}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces A stack of dilated causal convolutional layers.}}{37}{figure.17}\protected@file@percent }
\newlabel{fig:dilated_cnn}{{17}{37}{A stack of dilated causal convolutional layers}{figure.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Workload Forecasting }{37}{subsection.2.5}\protected@file@percent }
\newlabel{ssec:workload_forecasting}{{2.5}{37}{Workload Forecasting }{subsection.2.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Cloud vs traditional computing.}}{38}{figure.18}\protected@file@percent }
\newlabel{fig:cloud_vs_traditional_computing}{{18}{38}{Cloud vs traditional computing}{figure.18}{}}
\citation{Seagull}
\citation{MicrosoftSSA}
\citation{GluonTS}
\citation{FacebookProphet}
\citation{Seagull}
\citation{AkamasCGP}
\@writefile{toc}{\contentsline {section}{\numberline {3}Proposed solution and approach }{40}{section.3}\protected@file@percent }
\newlabel{sec:proposed_solution}{{3}{40}{Proposed solution and approach }{section.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Solution architecture: the Tuner repeatedly reads the workload from the IT System and sends it to the Forecasting Module. When ready, the Tuner asks the Forecasting Module to predict the upcoming workload. Then, it uses the Stability Module to check whether the predicted workload is stable or not, eventually applying a new configuration to the IT System. }}{41}{figure.19}\protected@file@percent }
\newlabel{fig:modules_interaction}{{19}{41}{Solution architecture: the Tuner repeatedly reads the workload from the IT System and sends it to the Forecasting Module. When ready, the Tuner asks the Forecasting Module to predict the upcoming workload. Then, it uses the Stability Module to check whether the predicted workload is stable or not, eventually applying a new configuration to the IT System}{figure.19}{}}
\citation{Seagull}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Window stability outcomes. TP, FP, TN, FN stands for True Positive, False Positive, True Negative, and False negative respectively.}}{42}{table.2}\protected@file@percent }
\newlabel{table:stability_cases}{{2}{42}{Window stability outcomes. TP, FP, TN, FN stands for True Positive, False Positive, True Negative, and False negative respectively}{table.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Online Contextual Gaussian Process Tuner}{42}{subsection.3.1}\protected@file@percent }
\newlabel{ssec:online_cgp_tuner}{{3.1}{42}{Online Contextual Gaussian Process Tuner}{subsection.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Tuning flowchart.}}{45}{figure.20}\protected@file@percent }
\newlabel{fig:online_tuning_flowchart}{{20}{45}{Tuning flowchart}{figure.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Forecasting Module}{46}{subsection.3.2}\protected@file@percent }
\newlabel{ssec:forecasting_module}{{3.2}{46}{Forecasting Module}{subsection.3.2}{}}
\citation{GluonTS}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Forecasting Module JSON configuration. The \textit  {group} property was used to build a DeepAR multivariate model on the time series \textit  {n\_requests1} and \textit  {n\_requests2}. The \textit  {params} property takes any model-specific parameter.}}{48}{figure.21}\protected@file@percent }
\newlabel{fig:forecaster_cfg.png}{{21}{48}{Forecasting Module JSON configuration. The \textit {group} property was used to build a DeepAR multivariate model on the time series \textit {n\_requests1} and \textit {n\_requests2}. The \textit {params} property takes any model-specific parameter}{figure.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Stable Window Finder}{49}{subsection.3.3}\protected@file@percent }
\newlabel{ssec:stable_window_finder}{{3.3}{49}{Stable Window Finder}{subsection.3.3}{}}
\citation{SilhouetteCoefficient}
\citation{MeanShift}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Example of stable windows detected by Min-Max algorithm using a threshold of 6\%.}}{52}{figure.22}\protected@file@percent }
\newlabel{fig:threshold_selection}{{22}{52}{Example of stable windows detected by Min-Max algorithm using a threshold of 6\%}{figure.22}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Workload Characterization Module}{52}{subsection.3.4}\protected@file@percent }
\newlabel{ssec:workload_characterization_module}{{3.4}{52}{Workload Characterization Module}{subsection.3.4}{}}
\citation{AkamasCGP}
\citation{AkamasCGP}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experimental Setup }{55}{section.4}\protected@file@percent }
\newlabel{sec:exp_setup}{{4}{55}{Experimental Setup }{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Workload Forecasting }{55}{subsection.4.1}\protected@file@percent }
\newlabel{ssec:exp_workload_forecasting}{{4.1}{55}{Workload Forecasting }{subsection.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Per-forecast and incremental MAPE example of three models. The forecast shown in picture $(a)$ is given by configuration $0$.}}{57}{figure.23}\protected@file@percent }
\newlabel{fig:exp_setup_forecasting}{{23}{57}{Per-forecast and incremental MAPE example of three models. The forecast shown in picture $(a)$ is given by configuration $0$}{figure.23}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Naive forecasts (red) based on previous day value.}}}{57}{subfigure.23.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Per-forecast MAPE.}}}{57}{subfigure.23.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Incremental MAPE.}}}{57}{subfigure.23.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Stable Window Finder }{58}{subsection.4.2}\protected@file@percent }
\newlabel{ssec:exp_stable_wkld_finder}{{4.2}{58}{Stable Window Finder }{subsection.4.2}{}}
\citation{AkamasCGP}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Online Contextual Gaussian Process Tuner }{59}{subsection.4.3}\protected@file@percent }
\newlabel{ssec:exp_online_cgp}{{4.3}{59}{Online Contextual Gaussian Process Tuner }{subsection.4.3}{}}
\citation{AkamasCGP}
\citation{AkamasCGP}
\citation{Cassandra}
\citation{MongoDB}
\citation{TaxiDataset}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces Workload time series.}}{61}{figure.24}\protected@file@percent }
\newlabel{fig:time_series}{{24}{61}{Workload time series}{figure.24}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Daily pattern}}}{61}{subfigure.24.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Weekly pattern}}}{61}{subfigure.24.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Taxi requests}}}{61}{subfigure.24.3}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {Bank requests}}}{61}{subfigure.24.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces Zoomed daily pattern with increasing noise.}}{62}{figure.25}\protected@file@percent }
\newlabel{fig:daily_noises}{{25}{62}{Zoomed daily pattern with increasing noise}{figure.25}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Daily 0.02 stddev noise}}}{62}{subfigure.25.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Daily 0.04 stddev noise}}}{62}{subfigure.25.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Daily 0.08 stddev noise}}}{62}{subfigure.25.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Results }{63}{section.5}\protected@file@percent }
\newlabel{sec:results}{{5}{63}{Results }{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Forecasting}{63}{subsection.5.1}\protected@file@percent }
\newlabel{ssec:results_forecasting}{{5.1}{63}{Forecasting}{subsection.5.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}Daily Time Series}{63}{subsubsection.5.1.1}\protected@file@percent }
\newlabel{sssec:results_forecasting_daily}{{5.1.1}{63}{Daily Time Series}{subsubsection.5.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces Errors on daily pattern time series, with 0.02 std dev. noise.}}{64}{figure.26}\protected@file@percent }
\newlabel{fig:results_forecasting_daily_02}{{26}{64}{Errors on daily pattern time series, with 0.02 std dev. noise}{figure.26}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Per-forecast MAPE}}}{64}{subfigure.26.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Per-forecast RMSE}}}{64}{subfigure.26.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Incremental MAPE}}}{64}{subfigure.26.3}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {Incremental RMSE}}}{64}{subfigure.26.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces Qualitative comparison of DeepAR and MQCNN on daily pattern with 0.02 std dev. noise. The blue time series is the ground truth. The model forecasts are red-colored.}}{64}{figure.27}\protected@file@percent }
\newlabel{fig:results_forecasting_daily_02_mqcnn_deepar}{{27}{64}{Qualitative comparison of DeepAR and MQCNN on daily pattern with 0.02 std dev. noise. The blue time series is the ground truth. The model forecasts are red-colored}{figure.27}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {DeepAR forecasts}}}{64}{subfigure.27.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {MQCNN forecasts}}}{64}{subfigure.27.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Results on daily patterns with increasing noise. The daily model produces forecasts repeating data of the previous day.}}{65}{table.3}\protected@file@percent }
\newlabel{table:results_forecasting_daily_patterns}{{3}{65}{Results on daily patterns with increasing noise. The daily model produces forecasts repeating data of the previous day}{table.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces Errors on weekly pattern time series.}}{66}{figure.28}\protected@file@percent }
\newlabel{fig:results_forecasting_weekly}{{28}{66}{Errors on weekly pattern time series}{figure.28}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Per-forecast MAPE}}}{66}{subfigure.28.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Per-forecast RMSE}}}{66}{subfigure.28.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Incremental MAPE}}}{66}{subfigure.28.3}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {Incremental RMSE}}}{66}{subfigure.28.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.2}Weekly time series}{66}{subsubsection.5.1.2}\protected@file@percent }
\newlabel{sssec:results_forecasting_weekly}{{5.1.2}{66}{Weekly time series}{subsubsection.5.1.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Results on weekly pattern with increasing noise. The Weekly model produces forecasts repeating data of the previous week.}}{67}{table.4}\protected@file@percent }
\newlabel{table:results_forecasting_weekly}{{4}{67}{Results on weekly pattern with increasing noise. The Weekly model produces forecasts repeating data of the previous week}{table.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {29}{\ignorespaces Forecasting of MQCNN model on weekly time series. The ground truth is blue. The model forecasts are red-colored. }}{67}{figure.29}\protected@file@percent }
\newlabel{fig:results_forecasting_weekly_mqcnn}{{29}{67}{Forecasting of MQCNN model on weekly time series. The ground truth is blue. The model forecasts are red-colored}{figure.29}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Results on bank time series. The Weekly model produces forecasts repeating data of the previous week.}}{68}{table.5}\protected@file@percent }
\newlabel{table:results_forecasting_bank}{{5}{68}{Results on bank time series. The Weekly model produces forecasts repeating data of the previous week}{table.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.3}Real-world time series}{68}{subsubsection.5.1.3}\protected@file@percent }
\newlabel{sssec:results_forecasting_bank}{{5.1.3}{68}{Real-world time series}{subsubsection.5.1.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {30}{\ignorespaces Errors on weekly pattern time series.}}{69}{figure.30}\protected@file@percent }
\newlabel{fig:results_forecasting_bank}{{30}{69}{Errors on weekly pattern time series}{figure.30}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Per-forecast MAPE}}}{69}{subfigure.30.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Per-forecast RMSE}}}{69}{subfigure.30.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Incremental MAPE}}}{69}{subfigure.30.3}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {Incremental RMSE}}}{69}{subfigure.30.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {31}{\ignorespaces Impact of forecasting every 30 and 15 minutes respectively. The blue-colored time series is the ground truth. The model forecasts are red-colored.}}{69}{figure.31}\protected@file@percent }
\newlabel{fig:results_forecasting_bank_deepar}{{31}{69}{Impact of forecasting every 30 and 15 minutes respectively. The blue-colored time series is the ground truth. The model forecasts are red-colored}{figure.31}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {DeepAR with 30 minutes forecasting interval}}}{69}{subfigure.31.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {DeepAR with 15 minutes forecasting interval}}}{69}{subfigure.31.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {32}{\ignorespaces Prophet forecasting. The blue-colored time series is the ground truth. The model forecasts are red-colored.}}{70}{figure.32}\protected@file@percent }
\newlabel{fig:results_forecasting_bank_prophet}{{32}{70}{Prophet forecasting. The blue-colored time series is the ground truth. The model forecasts are red-colored}{figure.32}{}}
\citation{TaxiDataset}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Results on taxi time series with increasing noise. The daily model produces forecasts repeating data of the previous day. }}{71}{table.6}\protected@file@percent }
\newlabel{table:results_forecasting_taxi}{{6}{71}{Results on taxi time series with increasing noise. The daily model produces forecasts repeating data of the previous day}{table.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.4}Taxi time series}{71}{subsubsection.5.1.4}\protected@file@percent }
\newlabel{sssec:results_forecasting_taxi}{{5.1.4}{71}{Taxi time series}{subsubsection.5.1.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {33}{\ignorespaces Errors on taxi time series. DeepState per-forecasts errors are not shown as they are high, hiding the other errors.}}{72}{figure.33}\protected@file@percent }
\newlabel{fig:results_forecasting_taxi}{{33}{72}{Errors on taxi time series. DeepState per-forecasts errors are not shown as they are high, hiding the other errors}{figure.33}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Per-forecast MAPE}}}{72}{subfigure.33.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Per-forecast RMSE}}}{72}{subfigure.33.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Incremental MAPE}}}{72}{subfigure.33.3}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {Incremental RMSE}}}{72}{subfigure.33.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {34}{\ignorespaces Qualitative comparison of Prophet and DeepAR on taxi time series. The model forecasts are red-colored.}}{72}{figure.34}\protected@file@percent }
\newlabel{fig:results_forecasting_taxi_prophet_deepar}{{34}{72}{Qualitative comparison of Prophet and DeepAR on taxi time series. The model forecasts are red-colored}{figure.34}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Prophet forecasts}}}{72}{subfigure.34.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {DeepAR forecasts}}}{72}{subfigure.34.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.5}Forecasting results conclusions}{73}{subsubsection.5.1.5}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Training times on the Weekly time series. }}{74}{table.7}\protected@file@percent }
\newlabel{table:results_forecasting_training_times}{{7}{74}{Training times on the Weekly time series}{table.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Workload Characterization }{74}{subsection.5.2}\protected@file@percent }
\newlabel{ssec:results_wkld_characterization}{{5.2}{74}{Workload Characterization }{subsection.5.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {35}{\ignorespaces GMM clustering on time series $(d)$ (bank requests). Each color is a cluster (there are a total of 8 clusters). This image clearly shows how the low-demand zone is over-separated, which would lead to a less-effective usage of the collected experiments by the tuner.}}{75}{figure.35}\protected@file@percent }
\newlabel{fig:results_gmm}{{35}{75}{GMM clustering on time series $(d)$ (bank requests). Each color is a cluster (there are a total of 8 clusters). This image clearly shows how the low-demand zone is over-separated, which would lead to a less-effective usage of the collected experiments by the tuner}{figure.35}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Online Contextual Gaussian Process Tuner}{75}{subsection.5.3}\protected@file@percent }
\newlabel{ssec:results_online_cgp_tuner}{{5.3}{75}{Online Contextual Gaussian Process Tuner}{subsection.5.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {36}{\ignorespaces Results of clustering the workload using $k$-means. Points with the same color belong to the same cluster.}}{76}{figure.36}\protected@file@percent }
\newlabel{fig:results_clustering_kmeans}{{36}{76}{Results of clustering the workload using $k$-means. Points with the same color belong to the same cluster}{figure.36}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Daily pattern}}}{76}{subfigure.36.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Weekly pattern}}}{76}{subfigure.36.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Taxi requests}}}{76}{subfigure.36.3}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {Bank requests}}}{76}{subfigure.36.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {37}{\ignorespaces Results of clustering the workload using mean shift. Points with the same color belong to the same cluster.}}{77}{figure.37}\protected@file@percent }
\newlabel{fig:results_clustering_meanshift}{{37}{77}{Results of clustering the workload using mean shift. Points with the same color belong to the same cluster}{figure.37}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Daily pattern}}}{77}{subfigure.37.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Weekly pattern}}}{77}{subfigure.37.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Taxi requests}}}{77}{subfigure.37.3}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {Bank requests}}}{77}{subfigure.37.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {38}{\ignorespaces Online CGP references: Best tuner (yellow), Baseline tuner (green), and Worst tuner (red).}}{79}{figure.38}\protected@file@percent }
\newlabel{fig:results_onlinecgp_references}{{38}{79}{Online CGP references: Best tuner (yellow), Baseline tuner (green), and Worst tuner (red)}{figure.38}{}}
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces Summary of MongoDB tuning scenarios. }}{80}{table.8}\protected@file@percent }
\newlabel{table:results_tuning_scenarios}{{8}{80}{Summary of MongoDB tuning scenarios}{table.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {39}{\ignorespaces Results of scenario MBank3.}}{81}{figure.39}\protected@file@percent }
\newlabel{fig:results_cgp_bank1}{{39}{81}{Results of scenario MBank3}{figure.39}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Cumulative Reward}}}{81}{subfigure.39.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Cumulative Failures}}}{81}{subfigure.39.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {40}{\ignorespaces MBank3 scenario Time To Recover. The yellow line is the Baseline CR. DeepAR, Prophet, and Naive online tuners overlap, leading to a TTR equal to 21 iterations, i.e. 1.5 hours.}}{82}{figure.40}\protected@file@percent }
\newlabel{fig:results_cgp_bank3_ttr}{{40}{82}{MBank3 scenario Time To Recover. The yellow line is the Baseline CR. DeepAR, Prophet, and Naive online tuners overlap, leading to a TTR equal to 21 iterations, i.e. 1.5 hours}{figure.40}{}}
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces MongoDB tuning scenarios results on synthetic time series. }}{83}{table.9}\protected@file@percent }
\newlabel{table:results_mongo_synthetic}{{9}{83}{MongoDB tuning scenarios results on synthetic time series}{table.9}{}}
\@writefile{lot}{\contentsline {table}{\numberline {10}{\ignorespaces MongoDB tuning scenarios results on real time series.}}{84}{table.10}\protected@file@percent }
\newlabel{table:results_mongo_real}{{10}{84}{MongoDB tuning scenarios results on real time series}{table.10}{}}
\@writefile{lot}{\contentsline {table}{\numberline {11}{\ignorespaces Summary of MongoDB tuning scenarios. }}{85}{table.11}\protected@file@percent }
\newlabel{table:results_tuning_scenarios_cassandra}{{11}{85}{Summary of MongoDB tuning scenarios}{table.11}{}}
\@writefile{lot}{\contentsline {table}{\numberline {12}{\ignorespaces MongoDB tuning scenarios results on synthetic time series. }}{86}{table.12}\protected@file@percent }
\newlabel{table:results_cassandra_synthetic}{{12}{86}{MongoDB tuning scenarios results on synthetic time series}{table.12}{}}
\@writefile{lot}{\contentsline {table}{\numberline {13}{\ignorespaces MongoDB tuning scenarios results on real time series.}}{87}{table.13}\protected@file@percent }
\newlabel{table:results_cassandra_real}{{13}{87}{MongoDB tuning scenarios results on real time series}{table.13}{}}
\@writefile{lot}{\contentsline {table}{\numberline {14}{\ignorespaces Tuning scenarios stability data, valid both for Cassandra and MongoDB scenarios. TS indicates the Time Series.}}{88}{table.14}\protected@file@percent }
\newlabel{table:results_stability}{{14}{88}{Tuning scenarios stability data, valid both for Cassandra and MongoDB scenarios. TS indicates the Time Series}{table.14}{}}
\citation{AkamasCGP}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusions and future work}{90}{section.6}\protected@file@percent }
\bibdata{bibliography.bib}
\bibcite{AkamasCGP}{1}
\bibcite{LearningToSample}{2}
\bibcite{OtterTune}{3}
\bibcite{OtterTune2}{4}
\bibcite{BO}{5}
\bibcite{CGPBanditOptimization}{6}
\bibcite{WorkloadCharacterization}{7}
\bibcite{PearsonCoefficient}{8}
\bibcite{ClusteringSurvey}{9}
\bibcite{PCA}{10}
\bibcite{WorkloadsPowerLaw}{11}
\bibcite{ClusterHomogeinitySeparation}{12}
\bibcite{FuzzyClustering}{13}
\bibcite{HierarchicalClustering}{14}
\bibcite{ImpossibleTheoremForClustering}{15}
\bibcite{kmeans++}{16}
\bibcite{MeanShift}{17}
\bibcite{OPTICS}{18}
\bibcite{MixtureModels}{19}
\bibcite{SilhouetteCoefficient}{20}
\bibcite{BayesianInformationCriterion}{21}
\bibcite{ForecastingSurvey}{22}
\bibcite{ExponentialSmoothingHoltCharles}{23}
\bibcite{ForecastingBoxJenkins}{24}
\bibcite{25YearsForecasting}{25}
\bibcite{DeepLearningForecastingSurvey}{26}
\bibcite{RNNLSTM}{27}
\bibcite{seq2seq}{28}
\bibcite{EncoderDecoder}{29}
\bibcite{DeepAR}{30}
\bibcite{DeepState}{31}
\bibcite{MAKRIDAKIS2018802}{32}
\bibcite{GluonTS}{33}
\bibcite{UberHybridES}{34}
\bibcite{M5Competition}{35}
\bibcite{FacebookProphet}{36}
\bibcite{MicrosoftSSA}{37}
\bibcite{ForecastingHyndmanAthanasopoulos}{38}
\bibcite{STL}{39}
\bibcite{DiscriminativeGenerativeModels}{40}
\bibcite{ExponentialSmoothingStateSpace}{41}
\bibcite{BoxJenkins}{42}
\bibcite{AutoForecasting}{43}
\bibcite{GAM}{44}
\bibcite{L-BFGS}{45}
\bibcite{RNNForecasting}{46}
\bibcite{RNN}{47}
\bibcite{VanishingGradient}{48}
\bibcite{MQCNN}{49}
\bibcite{NARX}{50}
\bibcite{Wavenet}{51}
\bibcite{CloudComputing}{52}
\bibcite{ArimaWorkloadPrediction}{53}
\bibcite{ArmaAutoscaling}{54}
\bibcite{WorkloadCharacterizationAndPrediction}{55}
\bibcite{LSTMLargeScaleWorkloadForecasting}{56}
\bibcite{Seagull}{57}
\bibcite{Cassandra}{58}
\bibcite{MongoDB}{59}
\bibcite{TaxiDataset}{60}
\bibstyle{ieeetr}
\gdef \@abspage@last{105}
